{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Humor_Detection_Report.ipynb","provenance":[],"collapsed_sections":["U4whYfCwcqtG","qufkoZsqdFBR","CQD1iIqBjpzg","APiyxwouj5Fe","3EXvrIJMgrG_","qb2RuiFai3wo","i-_hmCzelayZ","HPWvN7cHofn1","KCd3bmRP0tJd"],"toc_visible":true,"mount_file_id":"1i52M0Ta-MjZKT77rFgDfZHkpwaNSolqV","authorship_tag":"ABX9TyM4+v1wT9HVX94ZV3rwNbZ9"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU","widgets":{"application/vnd.jupyter.widget-state+json":{"40f538dc525043f5a580060e7fbcde4b":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_6ff7adc518ac44e4988307186ac80257","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_4f446394fc514c5587652c2c75902114","IPY_MODEL_4ea5b820cdb94af687861dc5ab743de4"]}},"6ff7adc518ac44e4988307186ac80257":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"4f446394fc514c5587652c2c75902114":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_3fc1af028d074ceda56fa23e4fc5c145","_dom_classes":[],"description":"","_model_name":"FloatProgressModel","bar_style":"success","max":1,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":1,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_4317379f3e684bc29fded05f562ae6df"}},"4ea5b820cdb94af687861dc5ab743de4":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_6647e6d536e245e1a2487cd2d2beafeb","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"â€‹","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 1293/? [13:07&lt;00:00,  1.64it/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_35350e2f2a2e42d2b71205cde36c2777"}},"3fc1af028d074ceda56fa23e4fc5c145":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"4317379f3e684bc29fded05f562ae6df":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"6647e6d536e245e1a2487cd2d2beafeb":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"35350e2f2a2e42d2b71205cde36c2777":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}}}}},"cells":[{"cell_type":"markdown","metadata":{"id":"x-s-5gRabhii"},"source":["#A pre-trained BERT model for humor detection\n","https://github.com/Moradnejad/ColBERT-Using-BERT-Sentence-Embedding-for-Humor-Detection"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":137},"id":"aCFv5pZedRjo","executionInfo":{"status":"ok","timestamp":1619631409377,"user_tz":-330,"elapsed":1357,"user":{"displayName":"RBDS","photoUrl":"https://lh5.googleusercontent.com/-C7oaGkZD4fU/AAAAAAAAAAI/AAAAAAAAAOg/VPdrPm2uRkk/s64/photo.jpg","userId":"06746346362961577685"}},"outputId":"4c43ccb4-573f-48c9-aa7e-bcee737def0f"},"source":["import pandas as pd\n","df_train = pd.read_csv('/content/drive/MyDrive/meme_classification_data/train.csv')\n","df_train.head(3)"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>ID</th>\n","      <th>image id</th>\n","      <th>text</th>\n","      <th>label</th>\n","      <th>label_num</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>1</td>\n","      <td>image_2455.jpg</td>\n","      <td>- It is not our fight - Are we not part of thi...</td>\n","      <td>troll</td>\n","      <td>2</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>2</td>\n","      <td>image_3701.jpg</td>\n","      <td>THAT'S THE DIFFERENCE BETWEEN YOU AND ME  YOU...</td>\n","      <td>none</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>3</td>\n","      <td>image_4166.png</td>\n","      <td>- WHAT DO THE TITANIC AND THE SIXTH SENSE HAVE...</td>\n","      <td>none</td>\n","      <td>0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["   ID        image id  ...  label label_num\n","0   1  image_2455.jpg  ...  troll         2\n","1   2  image_3701.jpg  ...   none         0\n","2   3  image_4166.png  ...   none         0\n","\n","[3 rows x 5 columns]"]},"metadata":{"tags":[]},"execution_count":1}]},{"cell_type":"markdown","metadata":{"id":"U4whYfCwcqtG"},"source":["#Using the pre-trained model for classification of humor"]},{"cell_type":"markdown","metadata":{"id":"qufkoZsqdFBR"},"source":["##Loading the model "]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"drNyCFLIGcVA","executionInfo":{"status":"ok","timestamp":1619631460996,"user_tz":-330,"elapsed":37692,"user":{"displayName":"RBDS","photoUrl":"https://lh5.googleusercontent.com/-C7oaGkZD4fU/AAAAAAAAAAI/AAAAAAAAAOg/VPdrPm2uRkk/s64/photo.jpg","userId":"06746346362961577685"}},"outputId":"f9d2da0c-8e88-405f-9f02-652637bb6c9a"},"source":["# Download model from the github repo and make sure the directry structure is correct, otherwise modify it. \n","import keras\n","model = keras.models.load_model(\"/content/drive/MyDrive/models/colbert-trained/\")\n","model.summary()"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Model: \"functional_3\"\n","__________________________________________________________________________________________________\n","Layer (type)                    Output Shape         Param #     Connected to                     \n","==================================================================================================\n","input_19 (InputLayer)           [(None, 20)]         0                                            \n","__________________________________________________________________________________________________\n","input_20 (InputLayer)           [(None, 20)]         0                                            \n","__________________________________________________________________________________________________\n","input_21 (InputLayer)           [(None, 20)]         0                                            \n","__________________________________________________________________________________________________\n","input_22 (InputLayer)           [(None, 20)]         0                                            \n","__________________________________________________________________________________________________\n","input_23 (InputLayer)           [(None, 20)]         0                                            \n","__________________________________________________________________________________________________\n","input_24 (InputLayer)           [(None, 20)]         0                                            \n","__________________________________________________________________________________________________\n","input_25 (InputLayer)           [(None, 20)]         0                                            \n","__________________________________________________________________________________________________\n","input_26 (InputLayer)           [(None, 20)]         0                                            \n","__________________________________________________________________________________________________\n","input_27 (InputLayer)           [(None, 20)]         0                                            \n","__________________________________________________________________________________________________\n","input_28 (InputLayer)           [(None, 20)]         0                                            \n","__________________________________________________________________________________________________\n","input_29 (InputLayer)           [(None, 20)]         0                                            \n","__________________________________________________________________________________________________\n","input_30 (InputLayer)           [(None, 20)]         0                                            \n","__________________________________________________________________________________________________\n","input_31 (InputLayer)           [(None, 20)]         0                                            \n","__________________________________________________________________________________________________\n","input_32 (InputLayer)           [(None, 20)]         0                                            \n","__________________________________________________________________________________________________\n","input_33 (InputLayer)           [(None, 20)]         0                                            \n","__________________________________________________________________________________________________\n","input_34 (InputLayer)           [(None, 100)]        0                                            \n","__________________________________________________________________________________________________\n","input_35 (InputLayer)           [(None, 100)]        0                                            \n","__________________________________________________________________________________________________\n","input_36 (InputLayer)           [(None, 100)]        0                                            \n","__________________________________________________________________________________________________\n","bert (Custom>TFBertMainLayer)   multiple             109482240   input_19[0][0]                   \n","                                                                 input_20[0][0]                   \n","                                                                 input_21[0][0]                   \n","                                                                 input_22[0][0]                   \n","                                                                 input_23[0][0]                   \n","                                                                 input_24[0][0]                   \n","                                                                 input_25[0][0]                   \n","                                                                 input_26[0][0]                   \n","                                                                 input_27[0][0]                   \n","                                                                 input_28[0][0]                   \n","                                                                 input_29[0][0]                   \n","                                                                 input_30[0][0]                   \n","                                                                 input_31[0][0]                   \n","                                                                 input_32[0][0]                   \n","                                                                 input_33[0][0]                   \n","                                                                 input_34[0][0]                   \n","                                                                 input_35[0][0]                   \n","                                                                 input_36[0][0]                   \n","__________________________________________________________________________________________________\n","global_average_pooling1d_6 (Glo (None, 768)          0           bert[0][0]                       \n","__________________________________________________________________________________________________\n","global_average_pooling1d_7 (Glo (None, 768)          0           bert[1][0]                       \n","__________________________________________________________________________________________________\n","global_average_pooling1d_8 (Glo (None, 768)          0           bert[2][0]                       \n","__________________________________________________________________________________________________\n","global_average_pooling1d_9 (Glo (None, 768)          0           bert[3][0]                       \n","__________________________________________________________________________________________________\n","global_average_pooling1d_10 (Gl (None, 768)          0           bert[4][0]                       \n","__________________________________________________________________________________________________\n","global_average_pooling1d_11 (Gl (None, 768)          0           bert[5][0]                       \n","__________________________________________________________________________________________________\n","dense_15 (Dense)                (None, 32)           24608       global_average_pooling1d_6[0][0] \n","__________________________________________________________________________________________________\n","dense_17 (Dense)                (None, 32)           24608       global_average_pooling1d_7[0][0] \n","__________________________________________________________________________________________________\n","dense_19 (Dense)                (None, 32)           24608       global_average_pooling1d_8[0][0] \n","__________________________________________________________________________________________________\n","dense_21 (Dense)                (None, 32)           24608       global_average_pooling1d_9[0][0] \n","__________________________________________________________________________________________________\n","dense_23 (Dense)                (None, 32)           24608       global_average_pooling1d_10[0][0]\n","__________________________________________________________________________________________________\n","dense_25 (Dense)                (None, 256)          196864      global_average_pooling1d_11[0][0]\n","__________________________________________________________________________________________________\n","dropout_44 (Dropout)            (None, 32)           0           dense_15[0][0]                   \n","__________________________________________________________________________________________________\n","dropout_45 (Dropout)            (None, 32)           0           dense_17[0][0]                   \n","__________________________________________________________________________________________________\n","dropout_46 (Dropout)            (None, 32)           0           dense_19[0][0]                   \n","__________________________________________________________________________________________________\n","dropout_47 (Dropout)            (None, 32)           0           dense_21[0][0]                   \n","__________________________________________________________________________________________________\n","dropout_48 (Dropout)            (None, 32)           0           dense_23[0][0]                   \n","__________________________________________________________________________________________________\n","dropout_49 (Dropout)            (None, 256)          0           dense_25[0][0]                   \n","__________________________________________________________________________________________________\n","dense_16 (Dense)                (None, 8)            264         dropout_44[0][0]                 \n","__________________________________________________________________________________________________\n","dense_18 (Dense)                (None, 8)            264         dropout_45[0][0]                 \n","__________________________________________________________________________________________________\n","dense_20 (Dense)                (None, 8)            264         dropout_46[0][0]                 \n","__________________________________________________________________________________________________\n","dense_22 (Dense)                (None, 8)            264         dropout_47[0][0]                 \n","__________________________________________________________________________________________________\n","dense_24 (Dense)                (None, 8)            264         dropout_48[0][0]                 \n","__________________________________________________________________________________________________\n","dense_26 (Dense)                (None, 64)           16448       dropout_49[0][0]                 \n","__________________________________________________________________________________________________\n","concatenate_1 (Concatenate)     (None, 104)          0           dense_16[0][0]                   \n","                                                                 dense_18[0][0]                   \n","                                                                 dense_20[0][0]                   \n","                                                                 dense_22[0][0]                   \n","                                                                 dense_24[0][0]                   \n","                                                                 dense_26[0][0]                   \n","__________________________________________________________________________________________________\n","dense_27 (Dense)                (None, 512)          53760       concatenate_1[0][0]              \n","__________________________________________________________________________________________________\n","dropout_50 (Dropout)            (None, 512)          0           dense_27[0][0]                   \n","__________________________________________________________________________________________________\n","dense_28 (Dense)                (None, 256)          131328      dropout_50[0][0]                 \n","__________________________________________________________________________________________________\n","dense_29 (Dense)                (None, 1)            257         dense_28[0][0]                   \n","==================================================================================================\n","Total params: 110,005,257\n","Trainable params: 110,005,257\n","Non-trainable params: 0\n","__________________________________________________________________________________________________\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"CQD1iIqBjpzg"},"source":["##Labelling the data for the model"]},{"cell_type":"code","metadata":{"id":"7l2ZpSWuIhBm","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1619631523369,"user_tz":-330,"elapsed":1473,"user":{"displayName":"RBDS","photoUrl":"https://lh5.googleusercontent.com/-C7oaGkZD4fU/AAAAAAAAAAI/AAAAAAAAAOg/VPdrPm2uRkk/s64/photo.jpg","userId":"06746346362961577685"}},"outputId":"a3e65241-ffc5-4aa4-8f49-d0bd12891c6d"},"source":["#We drop the troll samples and use the classifier to test how well it performs in classification of humorous vs not humorous(none label)\n","def hu(label_num):\n","  if label_num == 0:\n","    return 'False'\n","  else:\n","    return 'True'\n","\n","df_train = df_train[df_train['label_num'] != 2]\n","df_train['Humor'] = df_train['label_num'].apply(hu)\n","df_train.shape"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(1293, 6)"]},"metadata":{"tags":[]},"execution_count":3}]},{"cell_type":"markdown","metadata":{"id":"APiyxwouj5Fe"},"source":["##Pre-processing the text for the model"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Tn07l1mKcoz1","executionInfo":{"status":"ok","timestamp":1619631560437,"user_tz":-330,"elapsed":7217,"user":{"displayName":"RBDS","photoUrl":"https://lh5.googleusercontent.com/-C7oaGkZD4fU/AAAAAAAAAAI/AAAAAAAAAOg/VPdrPm2uRkk/s64/photo.jpg","userId":"06746346362961577685"}},"outputId":"d1f57c25-7f87-4331-f414-852554082bc9"},"source":["import subprocess\n","from ast import literal_eval\n","def run(command):\n","    process = subprocess.Popen(command, shell=True, stdout=subprocess.PIPE)\n","    out, err = process.communicate()\n","    print(out.decode('utf-8').strip())\n","\n","print('# CPU')\n","run('cat /proc/cpuinfo | egrep -m 1 \"^model name\"')\n","run('cat /proc/cpuinfo | egrep -m 1 \"^cpu MHz\"')\n","run('cat /proc/cpuinfo | egrep -m 1 \"^cpu cores\"')\n","\n","print('# RAM')\n","run('cat /proc/meminfo | egrep \"^MemTotal\"')\n","\n","print('# GPU')\n","run('lspci | grep VGA')\n","\n","print('# OS')\n","run('uname -a')\n","!pip install sentencepiece\n","!pip install transformers\n","import pandas as pd\n","import numpy as np\n","import sklearn\n","from sklearn.model_selection import GroupKFold\n","import matplotlib.pyplot as plt\n","from tqdm.notebook import tqdm\n","import tensorflow as tf\n","import tensorflow.keras.backend as K\n","from tensorflow import keras \n","\n","import os\n","from scipy.stats import spearmanr\n","from math import floor, ceil\n","from transformers import *\n","\n","import seaborn as sns\n","import string\n","import re    #for regex\n","\n","np.set_printoptions(suppress=True)\n","print(tf.__version__)\n","training_sample_count = 1991 \n","test_count = 600\n","\n","MAX_SENTENCE_LENGTH = 20\n","MAX_SENTENCES = 5\n","MAX_LENGTH = 100\n","\n"],"execution_count":null,"outputs":[{"output_type":"stream","text":["# CPU\n","model name\t: Intel(R) Xeon(R) CPU @ 2.20GHz\n","cpu MHz\t\t: 2199.998\n","cpu cores\t: 1\n","# RAM\n","MemTotal:       13333568 kB\n","# GPU\n","\n","# OS\n","Linux 5826f3470415 4.19.112+ #1 SMP Thu Jul 23 08:00:38 PDT 2020 x86_64 x86_64 x86_64 GNU/Linux\n","Requirement already satisfied: sentencepiece in /usr/local/lib/python3.7/dist-packages (0.1.95)\n","Requirement already satisfied: transformers in /usr/local/lib/python3.7/dist-packages (4.5.1)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from transformers) (20.9)\n","Requirement already satisfied: sacremoses in /usr/local/lib/python3.7/dist-packages (from transformers) (0.0.45)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.19.5)\n","Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from transformers) (3.10.1)\n","Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.41.1)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.0.12)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n","Requirement already satisfied: tokenizers<0.11,>=0.10.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.10.2)\n","Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n","Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->transformers) (2.4.7)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.0.1)\n","Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.15.0)\n","Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (7.1.2)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->transformers) (3.4.1)\n","Requirement already satisfied: typing-extensions>=3.6.4; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->transformers) (3.7.4.3)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2020.12.5)\n","2.4.1\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"_1yJ1PTVfjF0","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1619631571011,"user_tz":-330,"elapsed":1260,"user":{"displayName":"RBDS","photoUrl":"https://lh5.googleusercontent.com/-C7oaGkZD4fU/AAAAAAAAAAI/AAAAAAAAAOg/VPdrPm2uRkk/s64/photo.jpg","userId":"06746346362961577685"}},"outputId":"5db022f7-bcc0-437e-8234-4c65c37ef31d"},"source":["output_categories = ['Humor']\n","input_categories = ['text']\n","from transformers import BertTokenizer\n","\n","MODEL_TYPE = 'bert-base-uncased'\n","tokenizer = BertTokenizer.from_pretrained(MODEL_TYPE)\n","\n","import nltk\n","nltk.download('punkt')\n","from nltk.tokenize import sent_tokenize\n","\n","def return_id(str1, str2, truncation_strategy, length):\n","\n","    inputs = tokenizer.encode_plus(str1, str2,\n","        add_special_tokens=True,\n","        max_length=length,\n","        truncation_strategy=truncation_strategy)\n","\n","    input_ids =  inputs[\"input_ids\"]\n","    input_masks = [1] * len(input_ids)\n","    input_segments = inputs[\"token_type_ids\"]\n","    padding_length = length - len(input_ids)\n","    padding_id = tokenizer.pad_token_id\n","    input_ids = input_ids + ([padding_id] * padding_length)\n","    input_masks = input_masks + ([0] * padding_length)\n","    input_segments = input_segments + ([0] * padding_length)\n","\n","    return [input_ids, input_masks, input_segments]\n","\n","\n","def compute_input_arrays(df, columns, tokenizer):\n","    model_input = []\n","    for xx in range((MAX_SENTENCES*3)+3):\n","        model_input.append([])\n","    \n","    for _, row in tqdm(df[columns].iterrows()):\n","        i = 0\n","        \n","        # sent\n","        sentences = sent_tokenize(row.text)\n","        for xx in range(MAX_SENTENCES):\n","            s = sentences[xx] if xx<len(sentences) else ''\n","            ids_q, masks_q, segments_q = return_id(s, None, 'longest_first', MAX_SENTENCE_LENGTH)\n","            model_input[i].append(ids_q)\n","            i+=1\n","            model_input[i].append(masks_q)\n","            i+=1\n","            model_input[i].append(segments_q)\n","            i+=1\n","        \n","        # full row\n","        ids_q, masks_q, segments_q = return_id(row.text, None, 'longest_first', MAX_LENGTH)\n","        model_input[i].append(ids_q)\n","        i+=1\n","        model_input[i].append(masks_q)\n","        i+=1\n","        model_input[i].append(segments_q)\n","        \n","    for xx in range((MAX_SENTENCES*3)+3):\n","        model_input[xx] = np.asarray(model_input[xx], dtype=np.int32)\n","        \n","    print(model_input[0].shape)\n","    return model_input"],"execution_count":null,"outputs":[{"output_type":"stream","text":["[nltk_data] Downloading package punkt to /root/nltk_data...\n","[nltk_data]   Package punkt is already up-to-date!\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":120,"referenced_widgets":["40f538dc525043f5a580060e7fbcde4b","6ff7adc518ac44e4988307186ac80257","4f446394fc514c5587652c2c75902114","4ea5b820cdb94af687861dc5ab743de4","3fc1af028d074ceda56fa23e4fc5c145","4317379f3e684bc29fded05f562ae6df","6647e6d536e245e1a2487cd2d2beafeb","35350e2f2a2e42d2b71205cde36c2777"]},"id":"dMwbcLICfZj4","executionInfo":{"status":"ok","timestamp":1619631581382,"user_tz":-330,"elapsed":3615,"user":{"displayName":"RBDS","photoUrl":"https://lh5.googleusercontent.com/-C7oaGkZD4fU/AAAAAAAAAAI/AAAAAAAAAOg/VPdrPm2uRkk/s64/photo.jpg","userId":"06746346362961577685"}},"outputId":"687ace52-6294-4098-fdfa-b578257e2639"},"source":["train_inputs = compute_input_arrays(df_train, input_categories, tokenizer)"],"execution_count":null,"outputs":[{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"40f538dc525043f5a580060e7fbcde4b","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"],"name":"stderr"},{"output_type":"stream","text":["\n","(1293, 20)\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"3EXvrIJMgrG_"},"source":["##Performance of model"]},{"cell_type":"code","metadata":{"id":"q5ToIBF4fZne","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1619631610798,"user_tz":-330,"elapsed":21309,"user":{"displayName":"RBDS","photoUrl":"https://lh5.googleusercontent.com/-C7oaGkZD4fU/AAAAAAAAAAI/AAAAAAAAAOg/VPdrPm2uRkk/s64/photo.jpg","userId":"06746346362961577685"}},"outputId":"861e4623-3c00-46e3-9fa0-3c77f391a771"},"source":["from sklearn.metrics import classification_report\n","\n","y_pred = model.predict(train_inputs)\n","cutoff = y_pred.mean()\n","y_pred = np.where(y_pred > cutoff, 1, 0)\n","y_true = df_train['label_num'].values\n","\n","print(classification_report(y_true,y_pred))\n"],"execution_count":null,"outputs":[{"output_type":"stream","text":["              precision    recall  f1-score   support\n","\n","           0       0.47      0.16      0.24       604\n","           1       0.53      0.84      0.65       689\n","\n","    accuracy                           0.52      1293\n","   macro avg       0.50      0.50      0.45      1293\n","weighted avg       0.51      0.52      0.46      1293\n","\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"qb2RuiFai3wo"},"source":["#Extracting Features from the pre-trained model and training on the data for humor classification"]},{"cell_type":"markdown","metadata":{"id":"i-_hmCzelayZ"},"source":["##Extracting features"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"LFtq5foqGu_P","executionInfo":{"status":"ok","timestamp":1619631713303,"user_tz":-330,"elapsed":1831,"user":{"displayName":"RBDS","photoUrl":"https://lh5.googleusercontent.com/-C7oaGkZD4fU/AAAAAAAAAAI/AAAAAAAAAOg/VPdrPm2uRkk/s64/photo.jpg","userId":"06746346362961577685"}},"outputId":"4216f082-42d6-46ad-b439-87cc2322f47a"},"source":["from keras.models import Model\n","from keras.models import Sequential\n","from keras.layers import Dense, Dropout\n","from keras.optimizers import RMSprop,Adam\n","model= Model(inputs=model.input, outputs=model.layers[-2].output)\n","model.trainable = False\n","model.summary()\n","#We extract the 2nd last dense layer of the model and use it as features for training our model"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Model: \"model\"\n","__________________________________________________________________________________________________\n","Layer (type)                    Output Shape         Param #     Connected to                     \n","==================================================================================================\n","input_19 (InputLayer)           [(None, 20)]         0                                            \n","__________________________________________________________________________________________________\n","input_20 (InputLayer)           [(None, 20)]         0                                            \n","__________________________________________________________________________________________________\n","input_21 (InputLayer)           [(None, 20)]         0                                            \n","__________________________________________________________________________________________________\n","input_22 (InputLayer)           [(None, 20)]         0                                            \n","__________________________________________________________________________________________________\n","input_23 (InputLayer)           [(None, 20)]         0                                            \n","__________________________________________________________________________________________________\n","input_24 (InputLayer)           [(None, 20)]         0                                            \n","__________________________________________________________________________________________________\n","input_25 (InputLayer)           [(None, 20)]         0                                            \n","__________________________________________________________________________________________________\n","input_26 (InputLayer)           [(None, 20)]         0                                            \n","__________________________________________________________________________________________________\n","input_27 (InputLayer)           [(None, 20)]         0                                            \n","__________________________________________________________________________________________________\n","input_28 (InputLayer)           [(None, 20)]         0                                            \n","__________________________________________________________________________________________________\n","input_29 (InputLayer)           [(None, 20)]         0                                            \n","__________________________________________________________________________________________________\n","input_30 (InputLayer)           [(None, 20)]         0                                            \n","__________________________________________________________________________________________________\n","input_31 (InputLayer)           [(None, 20)]         0                                            \n","__________________________________________________________________________________________________\n","input_32 (InputLayer)           [(None, 20)]         0                                            \n","__________________________________________________________________________________________________\n","input_33 (InputLayer)           [(None, 20)]         0                                            \n","__________________________________________________________________________________________________\n","input_34 (InputLayer)           [(None, 100)]        0                                            \n","__________________________________________________________________________________________________\n","input_35 (InputLayer)           [(None, 100)]        0                                            \n","__________________________________________________________________________________________________\n","input_36 (InputLayer)           [(None, 100)]        0                                            \n","__________________________________________________________________________________________________\n","bert (Custom>TFBertMainLayer)   multiple             109482240   input_19[0][0]                   \n","                                                                 input_20[0][0]                   \n","                                                                 input_21[0][0]                   \n","                                                                 input_22[0][0]                   \n","                                                                 input_23[0][0]                   \n","                                                                 input_24[0][0]                   \n","                                                                 input_25[0][0]                   \n","                                                                 input_26[0][0]                   \n","                                                                 input_27[0][0]                   \n","                                                                 input_28[0][0]                   \n","                                                                 input_29[0][0]                   \n","                                                                 input_30[0][0]                   \n","                                                                 input_31[0][0]                   \n","                                                                 input_32[0][0]                   \n","                                                                 input_33[0][0]                   \n","                                                                 input_34[0][0]                   \n","                                                                 input_35[0][0]                   \n","                                                                 input_36[0][0]                   \n","__________________________________________________________________________________________________\n","global_average_pooling1d_6 (Glo (None, 768)          0           bert[0][0]                       \n","__________________________________________________________________________________________________\n","global_average_pooling1d_7 (Glo (None, 768)          0           bert[1][0]                       \n","__________________________________________________________________________________________________\n","global_average_pooling1d_8 (Glo (None, 768)          0           bert[2][0]                       \n","__________________________________________________________________________________________________\n","global_average_pooling1d_9 (Glo (None, 768)          0           bert[3][0]                       \n","__________________________________________________________________________________________________\n","global_average_pooling1d_10 (Gl (None, 768)          0           bert[4][0]                       \n","__________________________________________________________________________________________________\n","global_average_pooling1d_11 (Gl (None, 768)          0           bert[5][0]                       \n","__________________________________________________________________________________________________\n","dense_15 (Dense)                (None, 32)           24608       global_average_pooling1d_6[0][0] \n","__________________________________________________________________________________________________\n","dense_17 (Dense)                (None, 32)           24608       global_average_pooling1d_7[0][0] \n","__________________________________________________________________________________________________\n","dense_19 (Dense)                (None, 32)           24608       global_average_pooling1d_8[0][0] \n","__________________________________________________________________________________________________\n","dense_21 (Dense)                (None, 32)           24608       global_average_pooling1d_9[0][0] \n","__________________________________________________________________________________________________\n","dense_23 (Dense)                (None, 32)           24608       global_average_pooling1d_10[0][0]\n","__________________________________________________________________________________________________\n","dense_25 (Dense)                (None, 256)          196864      global_average_pooling1d_11[0][0]\n","__________________________________________________________________________________________________\n","dropout_44 (Dropout)            (None, 32)           0           dense_15[0][0]                   \n","__________________________________________________________________________________________________\n","dropout_45 (Dropout)            (None, 32)           0           dense_17[0][0]                   \n","__________________________________________________________________________________________________\n","dropout_46 (Dropout)            (None, 32)           0           dense_19[0][0]                   \n","__________________________________________________________________________________________________\n","dropout_47 (Dropout)            (None, 32)           0           dense_21[0][0]                   \n","__________________________________________________________________________________________________\n","dropout_48 (Dropout)            (None, 32)           0           dense_23[0][0]                   \n","__________________________________________________________________________________________________\n","dropout_49 (Dropout)            (None, 256)          0           dense_25[0][0]                   \n","__________________________________________________________________________________________________\n","dense_16 (Dense)                (None, 8)            264         dropout_44[0][0]                 \n","__________________________________________________________________________________________________\n","dense_18 (Dense)                (None, 8)            264         dropout_45[0][0]                 \n","__________________________________________________________________________________________________\n","dense_20 (Dense)                (None, 8)            264         dropout_46[0][0]                 \n","__________________________________________________________________________________________________\n","dense_22 (Dense)                (None, 8)            264         dropout_47[0][0]                 \n","__________________________________________________________________________________________________\n","dense_24 (Dense)                (None, 8)            264         dropout_48[0][0]                 \n","__________________________________________________________________________________________________\n","dense_26 (Dense)                (None, 64)           16448       dropout_49[0][0]                 \n","__________________________________________________________________________________________________\n","concatenate_1 (Concatenate)     (None, 104)          0           dense_16[0][0]                   \n","                                                                 dense_18[0][0]                   \n","                                                                 dense_20[0][0]                   \n","                                                                 dense_22[0][0]                   \n","                                                                 dense_24[0][0]                   \n","                                                                 dense_26[0][0]                   \n","__________________________________________________________________________________________________\n","dense_27 (Dense)                (None, 512)          53760       concatenate_1[0][0]              \n","__________________________________________________________________________________________________\n","dropout_50 (Dropout)            (None, 512)          0           dense_27[0][0]                   \n","__________________________________________________________________________________________________\n","dense_28 (Dense)                (None, 256)          131328      dropout_50[0][0]                 \n","==================================================================================================\n","Total params: 110,005,000\n","Trainable params: 0\n","Non-trainable params: 110,005,000\n","__________________________________________________________________________________________________\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"cX9zPK3efZ3k","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1619631938541,"user_tz":-330,"elapsed":16659,"user":{"displayName":"RBDS","photoUrl":"https://lh5.googleusercontent.com/-C7oaGkZD4fU/AAAAAAAAAAI/AAAAAAAAAOg/VPdrPm2uRkk/s64/photo.jpg","userId":"06746346362961577685"}},"outputId":"7a47643e-d6cf-473e-c7a6-89a3df944350"},"source":["humor_pred_feats = model.predict(train_inputs)\n","X = humor_pred_feats\n","y = df_train['label_num'].values\n","X.shape, y.shape"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["((1293, 256), (1293,))"]},"metadata":{"tags":[]},"execution_count":10}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"OJHX9ZCJdeD5","executionInfo":{"status":"ok","timestamp":1619631995347,"user_tz":-330,"elapsed":996,"user":{"displayName":"RBDS","photoUrl":"https://lh5.googleusercontent.com/-C7oaGkZD4fU/AAAAAAAAAAI/AAAAAAAAAOg/VPdrPm2uRkk/s64/photo.jpg","userId":"06746346362961577685"}},"outputId":"d5c5492f-4c19-4120-de39-aed8c7b68679"},"source":["np.count_nonzero(y), y.shape[0]\n","#Balanced data set"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(689, 1293)"]},"metadata":{"tags":[]},"execution_count":11}]},{"cell_type":"markdown","metadata":{"id":"cZ3lpjcHnjp-"},"source":["##Training features on neural network"]},{"cell_type":"code","metadata":{"id":"314KlvZRWMsI"},"source":["from sklearn.model_selection import train_test_split\n","X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n","X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.125, random_state=42)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"RF9HX0gAWae_","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1619632361431,"user_tz":-330,"elapsed":1441,"user":{"displayName":"RBDS","photoUrl":"https://lh5.googleusercontent.com/-C7oaGkZD4fU/AAAAAAAAAAI/AAAAAAAAAOg/VPdrPm2uRkk/s64/photo.jpg","userId":"06746346362961577685"}},"outputId":"b7d68b65-ba03-4f83-d702-5eba4fc67414"},"source":["from keras.models import Sequential\n","from keras.layers import Dense, Dropout\n","from keras.optimizers import RMSprop,Adam\n","model=Sequential() \n","model.add(Dense(20,activation='relu',input_shape=(256,),kernel_initializer='he_normal'))\n","model.add(Dense(10,activation='relu'))\n","model.add(Dense(1,activation='sigmoid'))\n","model.summary()"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Model: \"sequential_2\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","dense_5 (Dense)              (None, 20)                5140      \n","_________________________________________________________________\n","dense_6 (Dense)              (None, 10)                210       \n","_________________________________________________________________\n","dense_7 (Dense)              (None, 1)                 11        \n","=================================================================\n","Total params: 5,361\n","Trainable params: 5,361\n","Non-trainable params: 0\n","_________________________________________________________________\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"uPUGkYbQXIBW"},"source":["model.compile(loss='binary_crossentropy',\n","              optimizer=Adam(),\n","              metrics=['accuracy','AUC'])\n","\n","\n","history = model.fit(X_train, y_train,\n","                    batch_size=32,\n","                    epochs=60,\n","                    verbose=1,\n","                    validation_data=(X_val, y_val))\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"7VWOFWSrXQCn","executionInfo":{"status":"ok","timestamp":1619632599400,"user_tz":-330,"elapsed":1034,"user":{"displayName":"RBDS","photoUrl":"https://lh5.googleusercontent.com/-C7oaGkZD4fU/AAAAAAAAAAI/AAAAAAAAAOg/VPdrPm2uRkk/s64/photo.jpg","userId":"06746346362961577685"}},"outputId":"0c527fc8-24ff-4a6d-d8f3-8f75ee52cfde"},"source":["from sklearn.metrics import classification_report\n","y_pred = model.predict(X_test, batch_size=64, verbose=1)\n","p = y_pred.mean()\n","y_pred = np.where(y_pred >= p , 1 , 0)\n","print(y.shape, np.count_nonzero(y_pred))\n","print(classification_report(y_test,y_pred))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["5/5 [==============================] - 0s 2ms/step\n","(1293,) 122\n","              precision    recall  f1-score   support\n","\n","           0       0.46      0.54      0.50       116\n","           1       0.57      0.48      0.52       143\n","\n","    accuracy                           0.51       259\n","   macro avg       0.51      0.51      0.51       259\n","weighted avg       0.52      0.51      0.51       259\n","\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"z4lnoCbqoJtG"},"source":["##Training on SVM and XGB classifier"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"8noNzjarn0JW","executionInfo":{"status":"ok","timestamp":1619632710797,"user_tz":-330,"elapsed":1494,"user":{"displayName":"RBDS","photoUrl":"https://lh5.googleusercontent.com/-C7oaGkZD4fU/AAAAAAAAAAI/AAAAAAAAAOg/VPdrPm2uRkk/s64/photo.jpg","userId":"06746346362961577685"}},"outputId":"ef136b78-d9b6-4b1b-ddc8-1e9a97bfaf1a"},"source":["from sklearn.model_selection import train_test_split\n","X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n","X_train.shape,X_test.shape"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["((1034, 256), (259, 256))"]},"metadata":{"tags":[]},"execution_count":30}]},{"cell_type":"code","metadata":{"id":"T_Vr7qbSn0eX"},"source":["import numpy as np\n","import pandas as pd\n","from sklearn.svm import SVC\n","from xgboost import XGBClassifier\n","from sklearn.metrics import classification_report"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"HPWvN7cHofn1"},"source":["###SVM"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"BKDlhYY_oHFD","executionInfo":{"status":"ok","timestamp":1619632900759,"user_tz":-330,"elapsed":2298,"user":{"displayName":"RBDS","photoUrl":"https://lh5.googleusercontent.com/-C7oaGkZD4fU/AAAAAAAAAAI/AAAAAAAAAOg/VPdrPm2uRkk/s64/photo.jpg","userId":"06746346362961577685"}},"outputId":"05dbe936-ad97-4e01-c933-d166b5c77633"},"source":["#model = SVC(kernel = 'rbf') # 0.02 f1 on class 0\n","model = SVC(kernel = 'linear') # Best performance\n","#model = SVC(kernel = 'poly', degree = 8)\n","model.fit(X_train, y_train)\n","y_pred = model.predict(X_test)\n","print(classification_report(y_test, y_pred))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["              precision    recall  f1-score   support\n","\n","           0       0.54      0.33      0.41       116\n","           1       0.59      0.77      0.66       143\n","\n","    accuracy                           0.57       259\n","   macro avg       0.56      0.55      0.54       259\n","weighted avg       0.56      0.57      0.55       259\n","\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"MfoC6SBfpaKc"},"source":["###XGB Classifier"]},{"cell_type":"code","metadata":{"id":"6CdJ0a1yn1bJ","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1619632951356,"user_tz":-330,"elapsed":2484,"user":{"displayName":"RBDS","photoUrl":"https://lh5.googleusercontent.com/-C7oaGkZD4fU/AAAAAAAAAAI/AAAAAAAAAOg/VPdrPm2uRkk/s64/photo.jpg","userId":"06746346362961577685"}},"outputId":"ca052117-3958-44bb-94c1-0a79dd6659f9"},"source":["#model = SVC(kernel = 'rbf') # 0.02 f1 on class 0\n","model = XGBClassifier()# Best performance\n","#model = SVC(kernel = 'poly', degree = 8)\n","model.fit(X_train, y_train)\n","y_pred = model.predict(X_test)\n","print(classification_report(y_test, y_pred))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["              precision    recall  f1-score   support\n","\n","           0       0.51      0.47      0.49       116\n","           1       0.60      0.64      0.62       143\n","\n","    accuracy                           0.56       259\n","   macro avg       0.56      0.56      0.56       259\n","weighted avg       0.56      0.56      0.56       259\n","\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"KCd3bmRP0tJd"},"source":["#Saving the features"]},{"cell_type":"code","metadata":{"id":"zxqbfztn1ZNS"},"source":["humor_train = pd.DataFrame(X, columns = range(256))\n","humor_train.to_csv('/content/drive/MyDrive/meme_classification_data/train_humor_feats.csv', index=False)"],"execution_count":null,"outputs":[]}]}