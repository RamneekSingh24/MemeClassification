{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Humor+Sentiment_Report.ipynb","provenance":[],"collapsed_sections":["HPz6cpO3PV2s","BTw1jpYXPrep","mXiGCId1RcrB","Tq3MuvgEUv0b"],"toc_visible":true,"mount_file_id":"1MjUEVAyrIrvnWBSDkoc0GtLOJl5xVUiw","authorship_tag":"ABX9TyPHpK+XvESrqZFnPZKvyMgM"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","metadata":{"id":"HPz6cpO3PV2s"},"source":["#We combine the features extracted from pre-trained BERT humor detection and sentiment analysis models and train them on our data for the tri-classification task\n","\n","We have total 1024 features/sample, 768 from sentiment model and 256 from humor model"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":142},"id":"u1kCVwfqPfKy","executionInfo":{"status":"ok","timestamp":1619872854797,"user_tz":-330,"elapsed":1537,"user":{"displayName":"RBDS","photoUrl":"https://lh5.googleusercontent.com/-C7oaGkZD4fU/AAAAAAAAAAI/AAAAAAAAAOg/VPdrPm2uRkk/s64/photo.jpg","userId":"06746346362961577685"}},"outputId":"c4bab1ee-a59e-4e73-f3cd-325b4ab8a68e"},"source":["import pandas as pd\n","df_train = pd.read_csv('/content/drive/MyDrive/meme_classification_data/train.csv')\n","df_train.head(3)"],"execution_count":1,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>ID</th>\n","      <th>image id</th>\n","      <th>text</th>\n","      <th>label</th>\n","      <th>label_num</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>1</td>\n","      <td>image_2455.jpg</td>\n","      <td>- It is not our fight - Are we not part of thi...</td>\n","      <td>troll</td>\n","      <td>2</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>2</td>\n","      <td>image_3701.jpg</td>\n","      <td>THAT'S THE DIFFERENCE BETWEEN YOU AND ME  YOU...</td>\n","      <td>none</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>3</td>\n","      <td>image_4166.png</td>\n","      <td>- WHAT DO THE TITANIC AND THE SIXTH SENSE HAVE...</td>\n","      <td>none</td>\n","      <td>0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["   ID        image id  ...  label label_num\n","0   1  image_2455.jpg  ...  troll         2\n","1   2  image_3701.jpg  ...   none         0\n","2   3  image_4166.png  ...   none         0\n","\n","[3 rows x 5 columns]"]},"metadata":{"tags":[]},"execution_count":1}]},{"cell_type":"markdown","metadata":{"id":"BTw1jpYXPrep"},"source":["#Loading Features and combining"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"x9mptFPJP6uI","executionInfo":{"status":"ok","timestamp":1619872860205,"user_tz":-330,"elapsed":3484,"user":{"displayName":"RBDS","photoUrl":"https://lh5.googleusercontent.com/-C7oaGkZD4fU/AAAAAAAAAAI/AAAAAAAAAOg/VPdrPm2uRkk/s64/photo.jpg","userId":"06746346362961577685"}},"outputId":"4e18b9d3-d655-4b9f-df25-c93138397c28"},"source":["import numpy as np\n","df_sent = pd.read_csv('/content/drive/MyDrive/meme_classification_data_MMN/train_Sentiment.csv')\n","df_humor = pd.read_csv('/content/drive/MyDrive/meme_classification_data_MMN/train_Humor.csv')\n","X_sent = df_sent.values\n","X_humor = df_humor.values\n","X = np.concatenate((X_sent, X_humor), axis = 1)\n","y = df_train['label_num']\n","X.shape, y.shape"],"execution_count":2,"outputs":[{"output_type":"execute_result","data":{"text/plain":["((1991, 1024), (1991,))"]},"metadata":{"tags":[]},"execution_count":2}]},{"cell_type":"markdown","metadata":{"id":"mXiGCId1RcrB"},"source":["#Training NN on the features\n"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"DwNUVpVzRi5R","executionInfo":{"status":"ok","timestamp":1619872865741,"user_tz":-330,"elapsed":3967,"user":{"displayName":"RBDS","photoUrl":"https://lh5.googleusercontent.com/-C7oaGkZD4fU/AAAAAAAAAAI/AAAAAAAAAOg/VPdrPm2uRkk/s64/photo.jpg","userId":"06746346362961577685"}},"outputId":"4968ddb7-9460-461d-c528-1e9a24485f49"},"source":["from sklearn.model_selection import train_test_split\n","from keras.utils.np_utils import to_categorical   \n","categorical_labels = to_categorical(df_train['label_num'], num_classes=3)\n","X_train, X_test, y_train, y_test = train_test_split(X, categorical_labels, test_size=0.2, random_state=42)\n","X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.125, random_state=42)\n","X_train.shape, X_val.shape, X_test.shape, y_train.shape, y_val.shape, y_test.shape"],"execution_count":3,"outputs":[{"output_type":"execute_result","data":{"text/plain":["((1393, 1024), (199, 1024), (399, 1024), (1393, 3), (199, 3), (399, 3))"]},"metadata":{"tags":[]},"execution_count":3}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"aqcaAJ-jSXZZ","executionInfo":{"status":"ok","timestamp":1619872867845,"user_tz":-330,"elapsed":916,"user":{"displayName":"RBDS","photoUrl":"https://lh5.googleusercontent.com/-C7oaGkZD4fU/AAAAAAAAAAI/AAAAAAAAAOg/VPdrPm2uRkk/s64/photo.jpg","userId":"06746346362961577685"}},"outputId":"7bdf74c3-a8e2-49c8-fdee-87a09263718c"},"source":["from keras.models import Sequential\n","from keras.layers import Dense, Dropout\n","from keras.optimizers import RMSprop,Adam\n","model=Sequential() \n","model.add(Dense(50,activation='sigmoid',input_shape=(1024,),kernel_initializer='he_normal'))\n","model.add(Dropout(0.2))\n","#model.add(Dense(20,activation='sigmoid'))\n","model.add(Dense(5,activation='sigmoid'))\n","model.add(Dense(3,activation='softmax'))\n","model.summary()\n"],"execution_count":4,"outputs":[{"output_type":"stream","text":["Model: \"sequential\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","dense (Dense)                (None, 50)                51250     \n","_________________________________________________________________\n","dropout (Dropout)            (None, 50)                0         \n","_________________________________________________________________\n","dense_1 (Dense)              (None, 5)                 255       \n","_________________________________________________________________\n","dense_2 (Dense)              (None, 3)                 18        \n","=================================================================\n","Total params: 51,523\n","Trainable params: 51,523\n","Non-trainable params: 0\n","_________________________________________________________________\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"dyAbmxoUSibB","executionInfo":{"status":"ok","timestamp":1619644248656,"user_tz":-330,"elapsed":10426,"user":{"displayName":"RBDS","photoUrl":"https://lh5.googleusercontent.com/-C7oaGkZD4fU/AAAAAAAAAAI/AAAAAAAAAOg/VPdrPm2uRkk/s64/photo.jpg","userId":"06746346362961577685"}},"outputId":"a28f7d9a-ee02-498d-c904-3ddb1ec41164"},"source":["model.compile(loss='categorical_crossentropy',\n","              optimizer=Adam(),\n","              metrics=['accuracy','AUC'])\n","\n","\n","history = model.fit(X_train, y_train,\n","                    batch_size=32,\n","                    epochs=50,\n","                    verbose=1,\n","                    validation_data=(X_val, y_val))\n"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Epoch 1/50\n","44/44 [==============================] - 1s 10ms/step - loss: 1.1023 - accuracy: 0.3628 - auc: 0.5247 - val_loss: 1.1073 - val_accuracy: 0.3216 - val_auc: 0.5067\n","Epoch 2/50\n","44/44 [==============================] - 0s 3ms/step - loss: 1.0947 - accuracy: 0.3633 - auc: 0.5431 - val_loss: 1.0963 - val_accuracy: 0.3668 - val_auc: 0.5380\n","Epoch 3/50\n","44/44 [==============================] - 0s 4ms/step - loss: 1.0833 - accuracy: 0.3835 - auc: 0.5728 - val_loss: 1.0952 - val_accuracy: 0.4121 - val_auc: 0.5566\n","Epoch 4/50\n","44/44 [==============================] - 0s 3ms/step - loss: 1.0812 - accuracy: 0.3883 - auc: 0.5811 - val_loss: 1.1067 - val_accuracy: 0.3166 - val_auc: 0.5195\n","Epoch 5/50\n","44/44 [==============================] - 0s 4ms/step - loss: 1.0721 - accuracy: 0.4130 - auc: 0.5960 - val_loss: 1.0864 - val_accuracy: 0.4121 - val_auc: 0.5743\n","Epoch 6/50\n","44/44 [==============================] - 0s 4ms/step - loss: 1.0662 - accuracy: 0.4328 - auc: 0.6142 - val_loss: 1.1008 - val_accuracy: 0.3719 - val_auc: 0.5261\n","Epoch 7/50\n","44/44 [==============================] - 0s 4ms/step - loss: 1.0719 - accuracy: 0.4222 - auc: 0.6034 - val_loss: 1.0810 - val_accuracy: 0.4020 - val_auc: 0.5853\n","Epoch 8/50\n","44/44 [==============================] - 0s 4ms/step - loss: 1.0684 - accuracy: 0.4224 - auc: 0.6018 - val_loss: 1.0932 - val_accuracy: 0.3568 - val_auc: 0.5509\n","Epoch 9/50\n","44/44 [==============================] - 0s 4ms/step - loss: 1.0659 - accuracy: 0.4297 - auc: 0.6055 - val_loss: 1.0858 - val_accuracy: 0.3769 - val_auc: 0.5753\n","Epoch 10/50\n","44/44 [==============================] - 0s 4ms/step - loss: 1.0635 - accuracy: 0.4465 - auc: 0.6188 - val_loss: 1.1069 - val_accuracy: 0.3719 - val_auc: 0.5465\n","Epoch 11/50\n","44/44 [==============================] - 0s 4ms/step - loss: 1.0614 - accuracy: 0.4444 - auc: 0.6190 - val_loss: 1.1042 - val_accuracy: 0.3367 - val_auc: 0.5406\n","Epoch 12/50\n","44/44 [==============================] - 0s 4ms/step - loss: 1.0634 - accuracy: 0.4407 - auc: 0.6157 - val_loss: 1.0834 - val_accuracy: 0.3970 - val_auc: 0.5813\n","Epoch 13/50\n","44/44 [==============================] - 0s 4ms/step - loss: 1.0460 - accuracy: 0.4668 - auc: 0.6436 - val_loss: 1.1050 - val_accuracy: 0.3719 - val_auc: 0.5487\n","Epoch 14/50\n","44/44 [==============================] - 0s 3ms/step - loss: 1.0370 - accuracy: 0.4734 - auc: 0.6575 - val_loss: 1.0850 - val_accuracy: 0.3869 - val_auc: 0.5726\n","Epoch 15/50\n","44/44 [==============================] - 0s 4ms/step - loss: 1.0523 - accuracy: 0.4482 - auc: 0.6306 - val_loss: 1.0971 - val_accuracy: 0.3367 - val_auc: 0.5442\n","Epoch 16/50\n","44/44 [==============================] - 0s 4ms/step - loss: 1.0305 - accuracy: 0.4851 - auc: 0.6692 - val_loss: 1.0846 - val_accuracy: 0.3970 - val_auc: 0.5745\n","Epoch 17/50\n","44/44 [==============================] - 0s 4ms/step - loss: 1.0270 - accuracy: 0.4806 - auc: 0.6698 - val_loss: 1.0881 - val_accuracy: 0.3869 - val_auc: 0.5717\n","Epoch 18/50\n","44/44 [==============================] - 0s 4ms/step - loss: 1.0141 - accuracy: 0.5068 - auc: 0.6911 - val_loss: 1.1215 - val_accuracy: 0.3568 - val_auc: 0.5188\n","Epoch 19/50\n","44/44 [==============================] - 0s 4ms/step - loss: 1.0245 - accuracy: 0.4861 - auc: 0.6739 - val_loss: 1.1015 - val_accuracy: 0.3618 - val_auc: 0.5529\n","Epoch 20/50\n","44/44 [==============================] - 0s 4ms/step - loss: 1.0151 - accuracy: 0.5056 - auc: 0.6813 - val_loss: 1.0850 - val_accuracy: 0.4221 - val_auc: 0.5814\n","Epoch 21/50\n","44/44 [==============================] - 0s 4ms/step - loss: 1.0083 - accuracy: 0.5066 - auc: 0.6967 - val_loss: 1.0816 - val_accuracy: 0.4020 - val_auc: 0.5845\n","Epoch 22/50\n","44/44 [==============================] - 0s 4ms/step - loss: 1.0020 - accuracy: 0.5031 - auc: 0.6976 - val_loss: 1.0989 - val_accuracy: 0.3719 - val_auc: 0.5623\n","Epoch 23/50\n","44/44 [==============================] - 0s 4ms/step - loss: 0.9978 - accuracy: 0.5080 - auc: 0.7051 - val_loss: 1.1170 - val_accuracy: 0.3116 - val_auc: 0.5338\n","Epoch 24/50\n","44/44 [==============================] - 0s 4ms/step - loss: 0.9836 - accuracy: 0.5435 - auc: 0.7203 - val_loss: 1.0892 - val_accuracy: 0.4020 - val_auc: 0.5792\n","Epoch 25/50\n","44/44 [==============================] - 0s 4ms/step - loss: 0.9863 - accuracy: 0.5301 - auc: 0.7138 - val_loss: 1.1186 - val_accuracy: 0.3015 - val_auc: 0.5382\n","Epoch 26/50\n","44/44 [==============================] - 0s 4ms/step - loss: 0.9997 - accuracy: 0.5027 - auc: 0.6978 - val_loss: 1.1243 - val_accuracy: 0.3417 - val_auc: 0.5323\n","Epoch 27/50\n","44/44 [==============================] - 0s 4ms/step - loss: 0.9813 - accuracy: 0.5383 - auc: 0.7199 - val_loss: 1.0994 - val_accuracy: 0.3869 - val_auc: 0.5746\n","Epoch 28/50\n","44/44 [==============================] - 0s 4ms/step - loss: 0.9669 - accuracy: 0.5497 - auc: 0.7363 - val_loss: 1.1038 - val_accuracy: 0.3970 - val_auc: 0.5773\n","Epoch 29/50\n","44/44 [==============================] - 0s 4ms/step - loss: 0.9605 - accuracy: 0.5522 - auc: 0.7346 - val_loss: 1.0991 - val_accuracy: 0.4121 - val_auc: 0.5751\n","Epoch 30/50\n","44/44 [==============================] - 0s 4ms/step - loss: 0.9608 - accuracy: 0.5568 - auc: 0.7369 - val_loss: 1.0977 - val_accuracy: 0.4121 - val_auc: 0.5816\n","Epoch 31/50\n","44/44 [==============================] - 0s 3ms/step - loss: 0.9618 - accuracy: 0.5408 - auc: 0.7310 - val_loss: 1.1692 - val_accuracy: 0.3216 - val_auc: 0.5101\n","Epoch 32/50\n","44/44 [==============================] - 0s 4ms/step - loss: 0.9486 - accuracy: 0.5672 - auc: 0.7460 - val_loss: 1.1397 - val_accuracy: 0.3769 - val_auc: 0.5424\n","Epoch 33/50\n","44/44 [==============================] - 0s 3ms/step - loss: 0.9296 - accuracy: 0.5703 - auc: 0.7632 - val_loss: 1.1806 - val_accuracy: 0.3317 - val_auc: 0.5091\n","Epoch 34/50\n","44/44 [==============================] - 0s 4ms/step - loss: 0.9542 - accuracy: 0.5424 - auc: 0.7340 - val_loss: 1.1596 - val_accuracy: 0.3719 - val_auc: 0.5283\n","Epoch 35/50\n","44/44 [==============================] - 0s 4ms/step - loss: 0.9365 - accuracy: 0.5894 - auc: 0.7514 - val_loss: 1.1594 - val_accuracy: 0.3568 - val_auc: 0.5313\n","Epoch 36/50\n","44/44 [==============================] - 0s 4ms/step - loss: 0.9148 - accuracy: 0.5937 - auc: 0.7733 - val_loss: 1.1598 - val_accuracy: 0.3317 - val_auc: 0.5286\n","Epoch 37/50\n","44/44 [==============================] - 0s 4ms/step - loss: 0.9054 - accuracy: 0.5836 - auc: 0.7795 - val_loss: 1.1412 - val_accuracy: 0.3668 - val_auc: 0.5470\n","Epoch 38/50\n","44/44 [==============================] - 0s 4ms/step - loss: 0.8974 - accuracy: 0.6015 - auc: 0.7848 - val_loss: 1.1313 - val_accuracy: 0.3719 - val_auc: 0.5598\n","Epoch 39/50\n","44/44 [==============================] - 0s 4ms/step - loss: 0.8977 - accuracy: 0.6046 - auc: 0.7840 - val_loss: 1.1929 - val_accuracy: 0.3719 - val_auc: 0.5193\n","Epoch 40/50\n","44/44 [==============================] - 0s 4ms/step - loss: 0.8788 - accuracy: 0.6189 - auc: 0.7962 - val_loss: 1.1179 - val_accuracy: 0.4070 - val_auc: 0.5749\n","Epoch 41/50\n","44/44 [==============================] - 0s 4ms/step - loss: 0.8996 - accuracy: 0.5916 - auc: 0.7791 - val_loss: 1.1695 - val_accuracy: 0.3467 - val_auc: 0.5292\n","Epoch 42/50\n","44/44 [==============================] - 0s 4ms/step - loss: 0.8801 - accuracy: 0.6240 - auc: 0.7916 - val_loss: 1.1392 - val_accuracy: 0.3819 - val_auc: 0.5557\n","Epoch 43/50\n","44/44 [==============================] - 0s 4ms/step - loss: 0.9108 - accuracy: 0.5696 - auc: 0.7633 - val_loss: 1.1424 - val_accuracy: 0.3819 - val_auc: 0.5628\n","Epoch 44/50\n","44/44 [==============================] - 0s 4ms/step - loss: 0.8633 - accuracy: 0.6243 - auc: 0.8057 - val_loss: 1.1811 - val_accuracy: 0.3518 - val_auc: 0.5251\n","Epoch 45/50\n","44/44 [==============================] - 0s 4ms/step - loss: 0.8577 - accuracy: 0.6387 - auc: 0.8088 - val_loss: 1.1969 - val_accuracy: 0.3166 - val_auc: 0.5201\n","Epoch 46/50\n","44/44 [==============================] - 0s 4ms/step - loss: 0.8362 - accuracy: 0.6517 - auc: 0.8200 - val_loss: 1.1891 - val_accuracy: 0.3518 - val_auc: 0.5299\n","Epoch 47/50\n","44/44 [==============================] - 0s 4ms/step - loss: 0.8530 - accuracy: 0.6359 - auc: 0.8082 - val_loss: 1.1701 - val_accuracy: 0.3819 - val_auc: 0.5468\n","Epoch 48/50\n","44/44 [==============================] - 0s 3ms/step - loss: 0.8252 - accuracy: 0.6475 - auc: 0.8257 - val_loss: 1.1696 - val_accuracy: 0.3719 - val_auc: 0.5536\n","Epoch 49/50\n","44/44 [==============================] - 0s 4ms/step - loss: 0.8386 - accuracy: 0.6449 - auc: 0.8159 - val_loss: 1.2075 - val_accuracy: 0.3618 - val_auc: 0.5334\n","Epoch 50/50\n","44/44 [==============================] - 0s 4ms/step - loss: 0.7962 - accuracy: 0.6790 - auc: 0.8418 - val_loss: 1.2162 - val_accuracy: 0.3367 - val_auc: 0.5235\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"m8dtd0GlTAGT","executionInfo":{"status":"ok","timestamp":1619644251395,"user_tz":-330,"elapsed":1033,"user":{"displayName":"RBDS","photoUrl":"https://lh5.googleusercontent.com/-C7oaGkZD4fU/AAAAAAAAAAI/AAAAAAAAAOg/VPdrPm2uRkk/s64/photo.jpg","userId":"06746346362961577685"}},"outputId":"1b580c15-f4ce-4aa2-9e56-32d8f58e4d64"},"source":["from sklearn.metrics import classification_report\n","y_pred = model.predict(X_test, batch_size=64, verbose=1)\n","y_pred = np.argmax(y_pred, axis = 1)\n","y_true = np.argmax(y_test, axis = 1)\n","print(classification_report(y_true,y_pred))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["7/7 [==============================] - 0s 2ms/step\n","              precision    recall  f1-score   support\n","\n","           0       0.36      0.38      0.37       117\n","           1       0.43      0.32      0.37       136\n","           2       0.44      0.53      0.48       146\n","\n","    accuracy                           0.41       399\n","   macro avg       0.41      0.41      0.41       399\n","weighted avg       0.41      0.41      0.41       399\n","\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"Tq3MuvgEUv0b"},"source":["#Training on SVC, Tree Based Classifiers and Gradient Boost Classifiers"]},{"cell_type":"code","metadata":{"id":"r_xoA0WaUgxD","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1619872993896,"user_tz":-330,"elapsed":63873,"user":{"displayName":"RBDS","photoUrl":"https://lh5.googleusercontent.com/-C7oaGkZD4fU/AAAAAAAAAAI/AAAAAAAAAOg/VPdrPm2uRkk/s64/photo.jpg","userId":"06746346362961577685"}},"outputId":"67b79e72-74e0-4c76-9286-a9ffce4b3afd"},"source":["from sklearn.ensemble import RandomForestClassifier\n","from sklearn.ensemble import GradientBoostingClassifier\n","from sklearn.tree import DecisionTreeClassifier\n","from xgboost import XGBClassifier\n","from sklearn.svm import SVC\n","from sklearn.model_selection import train_test_split\n","from sklearn.metrics import classification_report\n","X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.2,random_state=42)\n","models=[SVC(kernel='rbf'), SVC(kernel = 'linear'), SVC(kernel = 'poly', degree = 6),RandomForestClassifier(),DecisionTreeClassifier(), XGBClassifier()]\n","names = ['SVM-rbf','SVM-linear','SVM-poly','Random-Forest','Decision-Tree', 'XGB']\n","for i in range(len(models)):\n","  models[i].fit(X_train,y_train)\n","  print(\"MODEL: \", names[i])\n","  print(\"On Train\")\n","  print(classification_report(y_train,models[i].predict(X_train)))\n","  print(\"On Test\")\n","  print(classification_report(y_test, models[i].predict(X_test)))"],"execution_count":5,"outputs":[{"output_type":"stream","text":["MODEL:  SVM-rbf\n","On Train\n","              precision    recall  f1-score   support\n","\n","           0       0.56      0.28      0.37       487\n","           1       0.50      0.58      0.54       553\n","           2       0.47      0.61      0.53       552\n","\n","    accuracy                           0.50      1592\n","   macro avg       0.51      0.49      0.48      1592\n","weighted avg       0.51      0.50      0.48      1592\n","\n","On Test\n","              precision    recall  f1-score   support\n","\n","           0       0.36      0.17      0.23       117\n","           1       0.39      0.47      0.43       136\n","           2       0.43      0.53      0.48       146\n","\n","    accuracy                           0.41       399\n","   macro avg       0.40      0.39      0.38       399\n","weighted avg       0.40      0.41      0.39       399\n","\n","MODEL:  SVM-linear\n","On Train\n","              precision    recall  f1-score   support\n","\n","           0       0.84      0.85      0.85       487\n","           1       0.86      0.85      0.85       553\n","           2       0.86      0.85      0.85       552\n","\n","    accuracy                           0.85      1592\n","   macro avg       0.85      0.85      0.85      1592\n","weighted avg       0.85      0.85      0.85      1592\n","\n","On Test\n","              precision    recall  f1-score   support\n","\n","           0       0.35      0.42      0.38       117\n","           1       0.37      0.35      0.36       136\n","           2       0.38      0.33      0.35       146\n","\n","    accuracy                           0.36       399\n","   macro avg       0.36      0.37      0.36       399\n","weighted avg       0.37      0.36      0.36       399\n","\n","MODEL:  SVM-poly\n","On Train\n","              precision    recall  f1-score   support\n","\n","           0       0.87      0.49      0.63       487\n","           1       0.79      0.59      0.68       553\n","           2       0.55      0.90      0.68       552\n","\n","    accuracy                           0.67      1592\n","   macro avg       0.74      0.66      0.66      1592\n","weighted avg       0.73      0.67      0.66      1592\n","\n","On Test\n","              precision    recall  f1-score   support\n","\n","           0       0.36      0.21      0.26       117\n","           1       0.38      0.26      0.31       136\n","           2       0.39      0.64      0.49       146\n","\n","    accuracy                           0.38       399\n","   macro avg       0.38      0.37      0.35       399\n","weighted avg       0.38      0.38      0.36       399\n","\n","MODEL:  Random-Forest\n","On Train\n","              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00       487\n","           1       1.00      1.00      1.00       553\n","           2       1.00      0.99      1.00       552\n","\n","    accuracy                           1.00      1592\n","   macro avg       1.00      1.00      1.00      1592\n","weighted avg       1.00      1.00      1.00      1592\n","\n","On Test\n","              precision    recall  f1-score   support\n","\n","           0       0.38      0.30      0.33       117\n","           1       0.37      0.41      0.39       136\n","           2       0.44      0.47      0.46       146\n","\n","    accuracy                           0.40       399\n","   macro avg       0.40      0.39      0.39       399\n","weighted avg       0.40      0.40      0.40       399\n","\n","MODEL:  Decision-Tree\n","On Train\n","              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00       487\n","           1       1.00      1.00      1.00       553\n","           2       1.00      0.99      1.00       552\n","\n","    accuracy                           1.00      1592\n","   macro avg       1.00      1.00      1.00      1592\n","weighted avg       1.00      1.00      1.00      1592\n","\n","On Test\n","              precision    recall  f1-score   support\n","\n","           0       0.32      0.32      0.32       117\n","           1       0.34      0.33      0.34       136\n","           2       0.44      0.45      0.45       146\n","\n","    accuracy                           0.37       399\n","   macro avg       0.37      0.37      0.37       399\n","weighted avg       0.37      0.37      0.37       399\n","\n","MODEL:  XGB\n","On Train\n","              precision    recall  f1-score   support\n","\n","           0       0.96      0.92      0.94       487\n","           1       0.95      0.94      0.95       553\n","           2       0.92      0.96      0.94       552\n","\n","    accuracy                           0.94      1592\n","   macro avg       0.94      0.94      0.94      1592\n","weighted avg       0.94      0.94      0.94      1592\n","\n","On Test\n","              precision    recall  f1-score   support\n","\n","           0       0.34      0.27      0.30       117\n","           1       0.41      0.44      0.43       136\n","           2       0.38      0.41      0.39       146\n","\n","    accuracy                           0.38       399\n","   macro avg       0.38      0.38      0.37       399\n","weighted avg       0.38      0.38      0.38       399\n","\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"WmLPcdThV0KR"},"source":["#PCA and trying models again"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"S3hTQX-zN1R6","executionInfo":{"status":"ok","timestamp":1619794028813,"user_tz":-330,"elapsed":3074,"user":{"displayName":"RBDS","photoUrl":"https://lh5.googleusercontent.com/-C7oaGkZD4fU/AAAAAAAAAAI/AAAAAAAAAOg/VPdrPm2uRkk/s64/photo.jpg","userId":"06746346362961577685"}},"outputId":"49d98511-272f-48c9-d63e-6c37a5799566"},"source":["import numpy as np\n","from sklearn.decomposition import PCA\n","pca = PCA(n_components=500)\n","pca.fit(X)\n","X = pca.transform(X)\n","X.shape"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(1991, 500)"]},"metadata":{"tags":[]},"execution_count":18}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"nSsv7jF8OwAh","executionInfo":{"status":"ok","timestamp":1619794067358,"user_tz":-330,"elapsed":37033,"user":{"displayName":"RBDS","photoUrl":"https://lh5.googleusercontent.com/-C7oaGkZD4fU/AAAAAAAAAAI/AAAAAAAAAOg/VPdrPm2uRkk/s64/photo.jpg","userId":"06746346362961577685"}},"outputId":"a721f98d-93be-4a85-91a3-d4d5f16a3573"},"source":["from sklearn.ensemble import RandomForestClassifier\n","from sklearn.ensemble import GradientBoostingClassifier\n","from sklearn.tree import DecisionTreeClassifier\n","from xgboost import XGBClassifier\n","from sklearn.svm import SVC\n","from sklearn.model_selection import train_test_split\n","from sklearn.metrics import classification_report\n","X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.2,random_state=42)\n","models=[SVC(kernel='rbf'), SVC(kernel = 'linear'), SVC(kernel = 'poly', degree = 6),RandomForestClassifier(),DecisionTreeClassifier(), XGBClassifier()]\n","names = ['SVM-rbf','SVM-linear','SVM-poly','Random-Forest','Decision-Tree', 'XGB']\n","for i in range(len(models)):\n","  models[i].fit(X_train,y_train)\n","  print(\"MODEL: \", names[i])\n","  print(\"On Train\")\n","  print(classification_report(y_train,models[i].predict(X_train)))\n","  print(\"On Test\")\n","  print(classification_report(y_test, models[i].predict(X_test)))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["MODEL:  SVM-rbf\n","On Train\n","              precision    recall  f1-score   support\n","\n","           0       0.75      0.49      0.59       487\n","           1       0.62      0.70      0.66       553\n","           2       0.59      0.68      0.63       552\n","\n","    accuracy                           0.63      1592\n","   macro avg       0.65      0.63      0.63      1592\n","weighted avg       0.65      0.63      0.63      1592\n","\n","On Test\n","              precision    recall  f1-score   support\n","\n","           0       0.42      0.25      0.31       117\n","           1       0.37      0.46      0.41       136\n","           2       0.43      0.48      0.45       146\n","\n","    accuracy                           0.40       399\n","   macro avg       0.41      0.39      0.39       399\n","weighted avg       0.41      0.40      0.40       399\n","\n","MODEL:  SVM-linear\n","On Train\n","              precision    recall  f1-score   support\n","\n","           0       0.74      0.77      0.75       487\n","           1       0.80      0.75      0.77       553\n","           2       0.74      0.76      0.75       552\n","\n","    accuracy                           0.76      1592\n","   macro avg       0.76      0.76      0.76      1592\n","weighted avg       0.76      0.76      0.76      1592\n","\n","On Test\n","              precision    recall  f1-score   support\n","\n","           0       0.38      0.45      0.41       117\n","           1       0.45      0.37      0.41       136\n","           2       0.43      0.44      0.44       146\n","\n","    accuracy                           0.42       399\n","   macro avg       0.42      0.42      0.42       399\n","weighted avg       0.42      0.42      0.42       399\n","\n","MODEL:  SVM-poly\n","On Train\n","              precision    recall  f1-score   support\n","\n","           0       1.00      0.36      0.52       487\n","           1       0.51      0.99      0.68       553\n","           2       0.90      0.56      0.69       552\n","\n","    accuracy                           0.65      1592\n","   macro avg       0.80      0.64      0.63      1592\n","weighted avg       0.80      0.65      0.64      1592\n","\n","On Test\n","              precision    recall  f1-score   support\n","\n","           0       0.32      0.10      0.15       117\n","           1       0.32      0.68      0.44       136\n","           2       0.41      0.21      0.27       146\n","\n","    accuracy                           0.34       399\n","   macro avg       0.35      0.33      0.29       399\n","weighted avg       0.35      0.34      0.30       399\n","\n","MODEL:  Random-Forest\n","On Train\n","              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00       487\n","           1       1.00      1.00      1.00       553\n","           2       1.00      1.00      1.00       552\n","\n","    accuracy                           1.00      1592\n","   macro avg       1.00      1.00      1.00      1592\n","weighted avg       1.00      1.00      1.00      1592\n","\n","On Test\n","              precision    recall  f1-score   support\n","\n","           0       0.26      0.15      0.19       117\n","           1       0.36      0.47      0.41       136\n","           2       0.34      0.36      0.35       146\n","\n","    accuracy                           0.34       399\n","   macro avg       0.32      0.33      0.32       399\n","weighted avg       0.32      0.34      0.32       399\n","\n","MODEL:  Decision-Tree\n","On Train\n","              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00       487\n","           1       1.00      1.00      1.00       553\n","           2       1.00      0.99      1.00       552\n","\n","    accuracy                           1.00      1592\n","   macro avg       1.00      1.00      1.00      1592\n","weighted avg       1.00      1.00      1.00      1592\n","\n","On Test\n","              precision    recall  f1-score   support\n","\n","           0       0.29      0.30      0.29       117\n","           1       0.32      0.34      0.33       136\n","           2       0.44      0.39      0.41       146\n","\n","    accuracy                           0.35       399\n","   macro avg       0.35      0.34      0.34       399\n","weighted avg       0.35      0.35      0.35       399\n","\n","MODEL:  XGB\n","On Train\n","              precision    recall  f1-score   support\n","\n","           0       0.99      0.99      0.99       487\n","           1       0.99      0.99      0.99       553\n","           2       0.99      1.00      0.99       552\n","\n","    accuracy                           0.99      1592\n","   macro avg       0.99      0.99      0.99      1592\n","weighted avg       0.99      0.99      0.99      1592\n","\n","On Test\n","              precision    recall  f1-score   support\n","\n","           0       0.31      0.27      0.29       117\n","           1       0.31      0.36      0.34       136\n","           2       0.36      0.35      0.36       146\n","\n","    accuracy                           0.33       399\n","   macro avg       0.33      0.33      0.33       399\n","weighted avg       0.33      0.33      0.33       399\n","\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Y4p2dqnAQHwa","executionInfo":{"status":"ok","timestamp":1619794143576,"user_tz":-330,"elapsed":2989,"user":{"displayName":"RBDS","photoUrl":"https://lh5.googleusercontent.com/-C7oaGkZD4fU/AAAAAAAAAAI/AAAAAAAAAOg/VPdrPm2uRkk/s64/photo.jpg","userId":"06746346362961577685"}},"outputId":"ad9b4fec-055f-467b-81d8-8bf56d040e5f"},"source":["from sklearn.model_selection import train_test_split\n","from keras.utils.np_utils import to_categorical   \n","categorical_labels = to_categorical(df_train['label_num'], num_classes=3)\n","X_train, X_test, y_train, y_test = train_test_split(X, categorical_labels, test_size=0.2, random_state=42)\n","X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.125, random_state=42)\n","X_train.shape, X_val.shape, X_test.shape, y_train.shape, y_val.shape, y_test.shape"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["((1393, 500), (199, 500), (399, 500), (1393, 3), (199, 3), (399, 3))"]},"metadata":{"tags":[]},"execution_count":21}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"09z7kXHfQMbR","executionInfo":{"status":"ok","timestamp":1619794321936,"user_tz":-330,"elapsed":954,"user":{"displayName":"RBDS","photoUrl":"https://lh5.googleusercontent.com/-C7oaGkZD4fU/AAAAAAAAAAI/AAAAAAAAAOg/VPdrPm2uRkk/s64/photo.jpg","userId":"06746346362961577685"}},"outputId":"52236bfe-390f-42a4-b749-8b71a6311c73"},"source":["from keras.models import Sequential\n","from keras.layers import Dense, Dropout\n","from keras.optimizers import RMSprop,Adam\n","model=Sequential() \n","model.add(Dense(50,activation='sigmoid',input_shape=(500,),kernel_initializer='he_normal'))\n","model.add(Dropout(0.1))\n","#model.add(Dense(20,activation='sigmoid'))\n","model.add(Dense(5,activation='sigmoid'))\n","model.add(Dense(3,activation='softmax'))\n","model.summary()"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Model: \"sequential_6\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","dense_23 (Dense)             (None, 50)                25050     \n","_________________________________________________________________\n","dropout_2 (Dropout)          (None, 50)                0         \n","_________________________________________________________________\n","dense_24 (Dense)             (None, 5)                 255       \n","_________________________________________________________________\n","dense_25 (Dense)             (None, 3)                 18        \n","=================================================================\n","Total params: 25,323\n","Trainable params: 25,323\n","Non-trainable params: 0\n","_________________________________________________________________\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"fmlm0aXWQQXa","executionInfo":{"status":"ok","timestamp":1619794329040,"user_tz":-330,"elapsed":5043,"user":{"displayName":"RBDS","photoUrl":"https://lh5.googleusercontent.com/-C7oaGkZD4fU/AAAAAAAAAAI/AAAAAAAAAOg/VPdrPm2uRkk/s64/photo.jpg","userId":"06746346362961577685"}},"outputId":"3a6c0b1e-f63c-4493-a893-e5d2b19a7d07"},"source":["model.compile(loss='categorical_crossentropy',\n","              optimizer=Adam(),\n","              metrics=['accuracy','AUC'])\n","\n","\n","history = model.fit(X_train, y_train,\n","                    batch_size=64,\n","                    epochs=25,\n","                    verbose=1,\n","                    validation_data=(X_val, y_val))\n"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Epoch 1/25\n","22/22 [==============================] - 1s 21ms/step - loss: 1.1494 - accuracy: 0.2976 - auc: 0.4740 - val_loss: 1.1008 - val_accuracy: 0.2915 - val_auc: 0.5148\n","Epoch 2/25\n","22/22 [==============================] - 0s 6ms/step - loss: 1.0951 - accuracy: 0.3512 - auc: 0.5309 - val_loss: 1.0937 - val_accuracy: 0.4171 - val_auc: 0.5454\n","Epoch 3/25\n","22/22 [==============================] - 0s 5ms/step - loss: 1.0885 - accuracy: 0.4017 - auc: 0.5747 - val_loss: 1.0907 - val_accuracy: 0.4020 - val_auc: 0.5626\n","Epoch 4/25\n","22/22 [==============================] - 0s 6ms/step - loss: 1.0743 - accuracy: 0.4465 - auc: 0.6339 - val_loss: 1.0886 - val_accuracy: 0.4020 - val_auc: 0.5690\n","Epoch 5/25\n","22/22 [==============================] - 0s 6ms/step - loss: 1.0731 - accuracy: 0.4470 - auc: 0.6273 - val_loss: 1.0871 - val_accuracy: 0.3970 - val_auc: 0.5713\n","Epoch 6/25\n","22/22 [==============================] - 0s 4ms/step - loss: 1.0661 - accuracy: 0.4582 - auc: 0.6453 - val_loss: 1.0873 - val_accuracy: 0.3869 - val_auc: 0.5693\n","Epoch 7/25\n","22/22 [==============================] - 0s 4ms/step - loss: 1.0687 - accuracy: 0.4393 - auc: 0.6302 - val_loss: 1.0875 - val_accuracy: 0.3819 - val_auc: 0.5684\n","Epoch 8/25\n","22/22 [==============================] - 0s 5ms/step - loss: 1.0521 - accuracy: 0.4974 - auc: 0.6768 - val_loss: 1.0855 - val_accuracy: 0.3970 - val_auc: 0.5732\n","Epoch 9/25\n","22/22 [==============================] - 0s 4ms/step - loss: 1.0528 - accuracy: 0.4671 - auc: 0.6647 - val_loss: 1.0855 - val_accuracy: 0.3920 - val_auc: 0.5707\n","Epoch 10/25\n","22/22 [==============================] - 0s 4ms/step - loss: 1.0433 - accuracy: 0.4974 - auc: 0.6838 - val_loss: 1.0848 - val_accuracy: 0.3920 - val_auc: 0.5744\n","Epoch 11/25\n","22/22 [==============================] - 0s 5ms/step - loss: 1.0338 - accuracy: 0.5161 - auc: 0.7031 - val_loss: 1.0866 - val_accuracy: 0.3920 - val_auc: 0.5700\n","Epoch 12/25\n","22/22 [==============================] - 0s 4ms/step - loss: 1.0316 - accuracy: 0.5251 - auc: 0.7062 - val_loss: 1.0857 - val_accuracy: 0.4121 - val_auc: 0.5724\n","Epoch 13/25\n","22/22 [==============================] - 0s 5ms/step - loss: 1.0239 - accuracy: 0.5256 - auc: 0.7153 - val_loss: 1.0853 - val_accuracy: 0.3920 - val_auc: 0.5747\n","Epoch 14/25\n","22/22 [==============================] - 0s 6ms/step - loss: 1.0186 - accuracy: 0.5366 - auc: 0.7191 - val_loss: 1.0853 - val_accuracy: 0.3920 - val_auc: 0.5750\n","Epoch 15/25\n","22/22 [==============================] - 0s 6ms/step - loss: 1.0146 - accuracy: 0.5325 - auc: 0.7242 - val_loss: 1.0881 - val_accuracy: 0.3719 - val_auc: 0.5689\n","Epoch 16/25\n","22/22 [==============================] - 0s 6ms/step - loss: 0.9953 - accuracy: 0.5652 - auc: 0.7446 - val_loss: 1.0888 - val_accuracy: 0.3769 - val_auc: 0.5672\n","Epoch 17/25\n","22/22 [==============================] - 0s 5ms/step - loss: 0.9975 - accuracy: 0.5598 - auc: 0.7387 - val_loss: 1.0907 - val_accuracy: 0.3769 - val_auc: 0.5638\n","Epoch 18/25\n","22/22 [==============================] - 0s 6ms/step - loss: 0.9740 - accuracy: 0.5892 - auc: 0.7712 - val_loss: 1.0907 - val_accuracy: 0.3769 - val_auc: 0.5659\n","Epoch 19/25\n","22/22 [==============================] - 0s 5ms/step - loss: 0.9707 - accuracy: 0.5818 - auc: 0.7668 - val_loss: 1.0925 - val_accuracy: 0.3869 - val_auc: 0.5654\n","Epoch 20/25\n","22/22 [==============================] - 0s 6ms/step - loss: 0.9662 - accuracy: 0.5764 - auc: 0.7596 - val_loss: 1.0957 - val_accuracy: 0.3769 - val_auc: 0.5633\n","Epoch 21/25\n","22/22 [==============================] - 0s 6ms/step - loss: 0.9452 - accuracy: 0.6089 - auc: 0.7885 - val_loss: 1.1010 - val_accuracy: 0.3769 - val_auc: 0.5576\n","Epoch 22/25\n","22/22 [==============================] - 0s 6ms/step - loss: 0.9519 - accuracy: 0.5934 - auc: 0.7722 - val_loss: 1.1002 - val_accuracy: 0.3920 - val_auc: 0.5624\n","Epoch 23/25\n","22/22 [==============================] - 0s 5ms/step - loss: 0.9379 - accuracy: 0.6112 - auc: 0.7828 - val_loss: 1.1075 - val_accuracy: 0.3618 - val_auc: 0.5556\n","Epoch 24/25\n","22/22 [==============================] - 0s 6ms/step - loss: 0.9242 - accuracy: 0.6279 - auc: 0.7964 - val_loss: 1.1119 - val_accuracy: 0.3618 - val_auc: 0.5548\n","Epoch 25/25\n","22/22 [==============================] - 0s 6ms/step - loss: 0.8998 - accuracy: 0.6612 - auc: 0.8142 - val_loss: 1.1127 - val_accuracy: 0.3668 - val_auc: 0.5579\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"AlZRiN_eQjhL","executionInfo":{"status":"ok","timestamp":1619794332646,"user_tz":-330,"elapsed":952,"user":{"displayName":"RBDS","photoUrl":"https://lh5.googleusercontent.com/-C7oaGkZD4fU/AAAAAAAAAAI/AAAAAAAAAOg/VPdrPm2uRkk/s64/photo.jpg","userId":"06746346362961577685"}},"outputId":"dfc09107-6b86-42c0-9120-f87fdf87423a"},"source":["from sklearn.metrics import classification_report\n","y_pred = model.predict(X_test, batch_size=64, verbose=1)\n","y_pred = np.argmax(y_pred, axis = 1)\n","y_true = np.argmax(y_test, axis = 1)\n","print(classification_report(y_true,y_pred))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["7/7 [==============================] - 0s 2ms/step\n","              precision    recall  f1-score   support\n","\n","           0       0.37      0.30      0.33       117\n","           1       0.42      0.40      0.41       136\n","           2       0.45      0.54      0.49       146\n","\n","    accuracy                           0.42       399\n","   macro avg       0.41      0.41      0.41       399\n","weighted avg       0.42      0.42      0.42       399\n","\n"],"name":"stdout"}]}]}